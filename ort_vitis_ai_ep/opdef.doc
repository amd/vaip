====================== scale ==================
op: scale
doc: This function computes the channel-wise dot product and adds the bias. For example, axis = -1:

    output[b, h, w, c] = input[b, h, w, c] * scale[c] + bias[c]

args: 
	input :: FLOAT32 REQUIRED
	The feature maps, can be x-dimension.

	scale :: FLOAT32 REQUIRED
	1-dimension, channel-wise.

	bias :: FLOAT32 OPTIONAL
	1-dimension, channel-wise.

attrs: 
	axis OPTIONAL
	`Datatype`: `int`

the axis of the input to implement scale

====================== exp ==================
op: exp
doc: This function computes the exponential of the input tensor element-wise.

    f(x) = exp(x)

args: 
	input :: FLOAT32 REQUIRED
	The feature maps, can be x-dimension.

attrs: 
====================== tile-fix ==================
op: tile-fix
doc: 
args: 
	input :: XINT32 REQUIRED
	4-dimension, N H W C

attrs: 
	reverse REQUIRED
	`Datatype`: `bool`

if reverse

	stride REQUIRED
	`Datatype`: `int`

stride for feature maps

====================== matmul ==================
op: matmul
doc: This operator is batched matmul.

    input[0] : [..., a, b]
    input[1] : [..., b, c]
    output   : [..., a, c]
    output[..., a, c] = sum_{i}
                      input[0][..., a, i] * input[1][..., i, b]
In this operator, ... denotes non-matrix dimensions,
and non-matrix dimensions are broadcasted.
For example,  if input[0].shape is `(1, j, m, n)`, and the other is `(k, 1, n, p)`, the out.shape would be `(k, j, m, p)`.
args: 
	input :: FLOAT32 REQUIRED_AND_REPEATED
	The feature maps, can be x-dimension.

	bias :: FLOAT32 OPTIONAL
	1-dimension

attrs: 
	transpose_a REQUIRED
	`Datatype`: `bool`

If true, input[0] is transposed before multiplication.

transpose(input[0]):

    [..., a, b] -> [..., b, a]


	transpose_b REQUIRED
	`Datatype`: `bool`

If true, input[1] is transposed before multiplication.

transpose(input[1]):

    [..., b, c] -> [..., c, b]


====================== stack ==================
op: stack
doc: Stacks a list of `rank-R` tensors into one `rank-(R+1)` tensor.

For example, given a list of length N of tensors of shape `(A, B, C)`;

if axis == 0 then the output tensor will have the shape `(N, A, B, C)`.

if axis == 1 then the output tensor will have the shape `(A, N, B, C)`.
args: 
	input :: FLOAT32 REQUIRED_AND_REPEATED
	The feature maps, can be x-dimension.

attrs: 
	axis REQUIRED
	`Datatype`: `int`

Dimension along which to pack. Negative values wrap around, so the valid range is [-(R+1), R+1)

====================== strided_slice ==================
op: strided_slice
doc: This operator is NumPy-style slicing syntax,

    output = input[begin:end:strides]

args: 
	input :: FLOAT32 REQUIRED
	The feature maps, can be x-dimension.

attrs: 
	begin REQUIRED
	`Datatype`: `vector<int>`

start location of slicing

	end REQUIRED
	`Datatype`: `vector<int>`

end location of slicing

	strides REQUIRED
	`Datatype`: `vector<int>`

strides of slicing

====================== softmax ==================
op: softmax
doc: Softmax Operator performs softmax along the dimension of axis.

    f(o) = exp(o) / sum_{i}(exp(i))
args: 
	input :: FLOAT32 REQUIRED
	The feature maps, can be x-dimension.

attrs: 
	axis REQUIRED
	`Datatype`: `int`

the dimension softmax would be performed on.

====================== batchnorm ==================
op: batchnorm
doc: implements batchnorm along the last dimension of input feature maps.

    output = (input - moving_mean) /
             sqrt(moving_var + epsilon) * gamma + beta
args: 
	input :: FLOAT32 REQUIRED
	The feature maps, can be x-dimension.

	gamma :: FLOAT32 REQUIRED
	`[in.shape[axis]]`

	beta :: FLOAT32 REQUIRED
	`[in.shape[axis]]`

	moving_mean :: FLOAT32 REQUIRED
	`[in.shape[axis]]`

	moving_var :: FLOAT32 REQUIRED
	`[in.shape[axis]]`

attrs: 
	axis REQUIRED
	`Datatype`: `int`

the axis of the input to implement batchnorm

	epsilon REQUIRED
	`Datatype`: `float`

a value added to the denominator for numerical stability

====================== pixel-shuffle-fix ==================
op: pixel-shuffle-fix
doc: 
args: 
	input :: FLOAT32 REQUIRED
	`[batch, in_height, in_width, in_channels]`.

attrs: 
	scale REQUIRED
	`Datatype`: `int`

scale for reorg

	reverse REQUIRED
	`Datatype`: `bool`

reorg or reversed reorg

====================== reorg-fix ==================
op: reorg-fix
doc: 
args: 
	input :: FLOAT32 REQUIRED
	`[batch, in_height, in_width, in_channels]`.

attrs: 
	scale REQUIRED
	`Datatype`: `int`

scale for reorg

	reverse REQUIRED
	`Datatype`: `bool`

reorg or reversed reorg

====================== reorg ==================
op: reorg
doc: Reorg Operator in YOLO.The implementations can be seen in https://github.com/intel/caffe/blob/master/include/caffe/layers/reorg_layer.hpp.
args: 
	input :: FLOAT32 REQUIRED
	`[batch, in_height, in_width, in_channels]`.

attrs: 
	scale REQUIRED
	`Datatype`: `int`

scale for reorg

	reverse REQUIRED
	`Datatype`: `bool`

reorg or reversed reorg

====================== concat-fix ==================
op: concat-fix
doc: 
args: 
	input :: XINT32 REQUIRED_AND_REPEATED
	The feature maps, can be x-dimension.

attrs: 
	axis REQUIRED
	`Datatype`: `int`

Dimension along which to concatenate.

====================== concat ==================
op: concat
doc: Concatenates different feature maps along the dimension `axis`.
All dimensions except axis must be equal.
args: 
	input :: FLOAT32 REQUIRED_AND_REPEATED
	The feature maps, can be x-dimension.

attrs: 
	axis REQUIRED
	`Datatype`: `int`

Dimension along which to concatenate.

====================== downsample-fix ==================
op: downsample-fix
doc: 
args: 
	input :: XINT32 REQUIRED
	The feature maps, can be x-dimension.

	size :: INT32 OPTIONAL
	Constant values denotes the shape of the output feature maps.

attrs: 
	mode REQUIRED
	`Datatype`: `string`

NEAREST, BILINEAR or TRILINEAR

	align_corners OPTIONAL
	`Datatype`: `bool`

If true, preserving the values at the corner pixels. Defaults to false.

	half_pixel_centers OPTIONAL
	`Datatype`: `bool`

If true, use half-pixel as centers.

	scale REQUIRED
	`DataType` : `std::vector<float>` {scale_w, scale_h}

====================== resize ==================
op: resize
doc: Operator resize the feature maps. For example, if the input is an image, and the shape of this image is [h, w, c], after 2d resize, the shape of the output image is [oh, ow, c].

    scale = (align_corners && out > 1)
            ? (in - 1) / (out - 1)
            : in / out
When given the index of output, how to find the corresponding input pixels:

    scaler = half_pixel_centers
             ? (out + 0.5) * scale - 0.5
             : out * scale
(1). for NEAREST resize:

    w_idx[ow] = min((w - 1),
                    align_corners ? round(scaler(ow))
                                  : floor(scaler(ow)))
    h_idx[oh] = min((h - 1),
                    align_corners ? round(scaler(oh))
                                  : floor(scaler(oh)))
    resize[oh, ow, c] = image[h_idx[oh], w_idx[ow], c]
(2). for BILINEAR resize:

    top = floor(scaler(oh))
    bottom = min(h - 1, top + 1)
    left = floor(scaler(ow))
    right = min(w - 1, left + 1)
    x_lerp = scaler(ow) - left
    y_lerp = scaler(oh) - top
    reisze[oh, ow, c] = (image[top, left, c] * (1 - x_lerp) +
                         image[top, right, c] * x_lerp) * (1 - y_lerp)
                        (image[bottom, left, c] * (1 - x_lerp) +
                         image[bottom, right, c] * x_lerp) * y_lerp

args: 
	input :: FLOAT32 REQUIRED
	The feature maps, can be x-dimension.

	size :: INT32 OPTIONAL
	Constant values denotes the shape of the output feature maps.

attrs: 
	mode REQUIRED
	`Datatype`: `string`

NEAREST, BILINEAR or TRILINEAR

	align_corners OPTIONAL
	`Datatype`: `bool`

If true, preserving the values at the corner pixels. Defaults to false.

	half_pixel_centers OPTIONAL
	`Datatype`: `bool`

If true, use half-pixel as centers.

	scale OPTIONAL
	`Datatype`: `vector<float>`

Constant values denotes the scale to resize the input. scale = out / in

====================== pad-fix ==================
op: pad-fix
doc: For example,

if the mode = "CONSTANT"

    input = [[1, 2],
             [3, 4]]
    paddings = [0, 1, 1, 0]
    output = [[0, 1, 2],
              [0, 3, 4],
              [0, 0, 0]]
if the mode = "REFLECT"

    input = [[1, 2],
             [3, 4]]
    paddings = [0, 1, 1, 0]
    output = [[2, 1, 2],
              [4, 3, 4],
              [2, 1, 2]]
if the mode = "SYMMETRIC"

    input = [[1, 2],
             [3, 4]]
    paddings = [0, 1, 1, 0]
    output = [[1, 1, 2],
              [3, 3, 4],
              [3, 3, 4]]

args: 
	input :: XINT32 REQUIRED
	The feature maps, can be x-dimension.

attrs: 
	paddings REQUIRED
	`Datatype`: `vector<int>`

pad along different dimensions, the number of value in paddings should be 2 times the number of dimensions of input feature maps.The n-th dimension of the output feature maps equals to:

    (n-th dim) out =
        paddings[2n] + (n-th dim) in + paddings[2n + 1]

	mode REQUIRED
	`Datatype`: `string`

`CONSTANT`,`REFLECT` or `SYMMETRIC`

	constant_values OPTIONAL
	`Datatype`: `vector<char>`

the value set into the padded locations, 2 * len(paddings)

====================== flatten ==================
op: flatten
doc: For example:

    input.shape  = [32, 5, 5, 2, 4]
    start_axis = 1
    end_axis = -1
    output.shape = [32, 200]
args: 
	input :: FLOAT32 REQUIRED
	The feature maps, can be x-dimension.

attrs: 
	start_axis REQUIRED
	`Datatype`: `int`

start axis to be flattened

	end_axis REQUIRED
	`Datatype`: `int`

end axis to be flattened

====================== eltwise-fix ==================
op: eltwise-fix
doc: 
args: 
	input :: XINT32 REQUIRED_AND_REPEATED
	The feature maps, can be x-dimension. eltwise-fix operator implements element-wise operations.

attrs: 
	nonlinear OPTIONAL
	`Datatype`: `string`

nonlinear type, "NONE", "RELU", "PRELU", "LEAKYRELU","RELU6". Default is "NONE"

	type OPTIONAL
	`Datatype`: `string`

eltwise type, "ADD", "MUL". Default is "ADD"

====================== transpose ==================
op: transpose
doc: For example:

    input.shape  = [32, 2, 64, 4]
    order = {0, 3, 2, 1}
    output = input.transpose([0, 3, 2, 1]
    output.shape = [32, 4, 64, 2]
args: 
	input :: FLOAT32 REQUIRED
	The feature maps, can be x-dimension.

attrs: 
	order REQUIRED
	`Datatype`: `vector<int>`

The order to be transposed.

====================== squeeze ==================
op: squeeze
doc: For example:

    input.shape  = [32, 2, 1, 1]
    axis = {2, 3}
    output.shape = [32, 2]
args: 
	input :: FLOAT32 REQUIRED
	The feature maps, can be x-dimension.

attrs: 
	axis OPTIONAL
	`Datatype`: `vector<int>`

The dimensions to be squeezed.
If axis is not specified, all dimensions equal to 1 would be squeezed.

====================== reshape-fix ==================
op: reshape-fix
doc: 
args: 
	input :: XINT32 REQUIRED
	x-dimension

attrs: 
	shape REQUIRED
	`Datatype`: `vector<int>`

shape

====================== transposed-depthwise-conv3d ==================
op: transposed-depthwise-conv3d
doc: Transposed depth-wise 3D convolution.


args: 
	input :: FLOAT32 REQUIRED
	An input tensor with shape `[batch, in_height, in_width, depth, in_channels]`.

	weights :: FLOAT32 REQUIRED
	A filter tensor with shape `[output_channels, kernel_height, kernel_width, kernel_depth, in_channels]`.

	bias :: FLOAT32 OPTIONAL
	A bias tensor with shape `[output_channels]`.

attrs: 
	kernel REQUIRED
	`Datatype`: `vector<int>`

The kernel sizes of the filter. The value must be: `{kernel_width, kernel_height, kernel_depth}`.

	stride REQUIRED
	`Datatype`: `vector<int>`

The strides of the filter. The value must be: `{stride_width, stride_height, stride_depth}`.

	dilation OPTIONAL
	`Datatype`: `vector<int>`

The dilation of the filter. The value must be: `{dilation_width, dilation_height, dilation_depth}`, The dilation in the batch or depth are 1 in default.

	pad_mode REQUIRED
	`Datatype`: `string`

We support 4 padding mode: `FLOOR, CEIL, SAME, VALID`. For example, when you parsing models from other frameworks, `caffe, pytorch->"FLOOR", tensorflow->"SAME" or "VALID"`.

	pad OPTIONAL
	`Datatype`: `vector<int>`

The padding sizes of input feature maps. The value must be `{left, right, top, bottom, near, far}`.

For transposed convolutions, the padding here denotes the `{kernel_size - 1 - actual_padding}`.This is an optional attribute, when the pad_mode is SAME or VALID, you don't need to specify this attribute.

====================== conv2d-fix ==================
op: conv2d-fix
doc: 
args: 
	input :: XINT32 REQUIRED
	An input tensor with shape `[batch, in_height, in_width, in_channels]`.

	weights :: XINT32 REQUIRED
	A filter tensor with shape `[output_channels, kernel_height, kernel_width, in_channels]`.

	bias :: XINT32 OPTIONAL
	A bias tensor with shape `[output_channels]`.

attrs: 
	kernel REQUIRED
	`Datatype`: `vector<int>`

The kernel sizes of the filter. The value must be: `{kernel_width, kernel_height}`.

	stride REQUIRED
	`Datatype`: `vector<int>`

The strides of the filter. The value must be: `{stride_width, stride_height}`.

	dilation OPTIONAL
	`Datatype`: `vector<int>`

The dilation of the filter. The value must be: `{dilation_width, dilation_height}`, The dilation in the batch or depth are 1 in default.

	pad OPTIONAL
	`Datatype`: `vector<int>`

The padding sizes of input feature maps. The value must be `{left, right, top, bottom}`.

For transposed convolutions, the padding here denotes the `{kernel_size - 1 - actual_padding}`.

	nonlinear OPTIONAL
	`Datatype`: `string`

nonlinear type, "NONE", "RELU", "PRELU", "LEAKYRELU","RELU6","HSIGMOID","HSWISH".

	hsigmoid_in OPTIONAL
	`Datatype`: `int`

fix_point of hsigmoid

	shift_hsigmoid OPTIONAL
	`Datatype`: `int`

shift value after hsigmoid

	shift_hswish OPTIONAL
	`Datatype`: `int`

shift value after hswish

====================== depthwise-conv3d-fix ==================
op: depthwise-conv3d-fix
doc: 
args: 
	input :: XINT32 REQUIRED
	An input tensor with shape `[batch, in_height, in_width, in_depth, in_channels]`.

	weights :: XINT32 REQUIRED
	A filter tensor with shape `[output_channels, kernel_height, kernel_width, kernel_depth, in_channels]`.

	bias :: XINT32 OPTIONAL
	A bias tensor with shape `[output_channels]`.

attrs: 
	kernel REQUIRED
	`Datatype`: `vector<int>`

The kernel sizes of the filter. The value must be: `{kernel_width, kernel_height}`.

	stride REQUIRED
	`Datatype`: `vector<int>`

The strides of the filter. The value must be: `{stride_width, stride_height}`.

	dilation OPTIONAL
	`Datatype`: `vector<int>`

The dilation of the filter. The value must be: `{dilation_width, dilation_height}`, The dilation in the batch or depth are 1 in default.

	pad OPTIONAL
	`Datatype`: `vector<int>`

The padding sizes of input feature maps. The value must be `{left, right, top, bottom}`.

For transposed convolutions, the padding here denotes the `{kernel_size - 1 - actual_padding}`.This is an optional attribute, when the pad_mode is SAME or VALID, you don't need to specify this attribute.

	nonlinear OPTIONAL
	`Datatype`: `string`

nonlinear type, "NONE", "RELU", "PRELU", "LEAKYRELU","RELU6","HSIGMOID","HSWISH".

====================== transposed-depthwise-conv2d-fix ==================
op: transposed-depthwise-conv2d-fix
doc: 
args: 
	input :: XINT32 REQUIRED
	An input tensor with shape `[batch, in_height, in_width, in_channels]`.

	weights :: XINT32 REQUIRED
	A filter tensor with shape `[output_channels, kernel_height, kernel_width, in_channels]`.

	bias :: XINT32 OPTIONAL
	A bias tensor with shape `[output_channels]`.

attrs: 
	kernel REQUIRED
	`Datatype`: `vector<int>`

The kernel sizes of the filter. The value must be: `{kernel_width, kernel_height}`.

	stride REQUIRED
	`Datatype`: `vector<int>`

The strides of the filter. The value must be: `{stride_width, stride_height}`.

	dilation OPTIONAL
	`Datatype`: `vector<int>`

The dilation of the filter. The value must be: `{dilation_width, dilation_height}`, The dilation in the batch or depth are 1 in default.

	pad OPTIONAL
	`Datatype`: `vector<int>`

The padding sizes of input feature maps. The value must be `{left, right, top, bottom}`.

For transposed convolutions, the padding here denotes the `{kernel_size - 1 - actual_padding}`.

	nonlinear OPTIONAL
	`Datatype`: `string`

nonlinear type, "NONE", "RELU", "PRELU", "LEAKYRELU","RELU6","HSIGMOID","HSWISH".

====================== transposed-conv2d-fix ==================
op: transposed-conv2d-fix
doc: 
args: 
	input :: XINT32 REQUIRED
	An input tensor with shape `[batch, in_height, in_width, in_channels]`.

	weights :: XINT32 REQUIRED
	A filter tensor with shape `[output_channels, kernel_height, kernel_width, in_channels]`.

	bias :: XINT32 OPTIONAL
	A bias tensor with shape `[output_channels]`.

attrs: 
	kernel REQUIRED
	`Datatype`: `vector<int>`

The kernel sizes of the filter. The value must be: `{kernel_width, kernel_height}`.

	stride REQUIRED
	`Datatype`: `vector<int>`

The strides of the filter. The value must be: `{stride_width, stride_height}`.

	dilation OPTIONAL
	`Datatype`: `vector<int>`

The dilation of the filter. The value must be: `{dilation_width, dilation_height}`, The dilation in the batch or depth are 1 in default.

	pad OPTIONAL
	`Datatype`: `vector<int>`

The padding sizes of input feature maps. The value must be `{left, right, top, bottom}`.

For transposed convolutions, the padding here denotes the `{kernel_size - 1 - actual_padding}`.

	nonlinear OPTIONAL
	`Datatype`: `string`

nonlinear type, "NONE", "RELU", "PRELU", "LEAKYRELU","RELU6","HSIGMOID","HSWISH".

====================== relu ==================
op: relu
doc: Computes the rectified linear element-wise:

    f(x) = max(0, x).

args: 
	input :: FLOAT32 REQUIRED
	The feature maps, can be x-dimension.

attrs: 
====================== reduction_product ==================
op: reduction_product
doc: Implement the product along each of the axis dimensions.
args: 
	input :: FLOAT32 REQUIRED
	The feature maps, can be x-dimension.

attrs: 
	axis REQUIRED
	`Datatype`: `vector<int>`

The dimensions to reduce.

	keep_dims REQUIRED
	`Datatype`: `bool`

specify whether the reduced dimension is kept or not.

====================== conv3d-fix ==================
op: conv3d-fix
doc: 
args: 
	input :: XINT32 REQUIRED
	An input tensor with shape `[batch, in_height, in_width, in_depth, in_channels]`.

	weights :: XINT32 REQUIRED
	A filter tensor with shape `[output_channels, kernel_height, kernel_width, kernel_depth, in_channels]`.

	bias :: XINT32 OPTIONAL
	A bias tensor with shape `[output_channels]`.

attrs: 
	kernel REQUIRED
	`Datatype`: `vector<int>`

The kernel sizes of the filter. The value must be: `{kernel_width, kernel_height}`.

	stride REQUIRED
	`Datatype`: `vector<int>`

The strides of the filter. The value must be: `{stride_width, stride_height}`.

	dilation OPTIONAL
	`Datatype`: `vector<int>`

The dilation of the filter. The value must be: `{dilation_width, dilation_height}`, The dilation in the batch or depth are 1 in default.

	pad OPTIONAL
	`Datatype`: `vector<int>`

The padding sizes of input feature maps. The value must be `{left, right, top, bottom}`.

For transposed convolutions, the padding here denotes the `{kernel_size - 1 - actual_padding}`.This is an optional attribute, when the pad_mode is SAME or VALID, you don't need to specify this attribute.

	nonlinear OPTIONAL
	`Datatype`: `string`

nonlinear type, "NONE", "RELU", "PRELU", "LEAKYRELU","RELU6","HSIGMOID","HSWISH".

	hsigmoid_in OPTIONAL
	`Datatype`: `int`

fix_point of hsigmoid

	shift_hsigmoid OPTIONAL
	`Datatype`: `int`

shift value after hsigmoid

	shift_hswish OPTIONAL
	`Datatype`: `int`

shift value after hswish

====================== const ==================
op: const
doc: A placeholder which stores the parameters, 
such as weights, bias, etc.

How to transform float-point values into vector<char>: 

    const std::vector<float> float_data = {...};
    std::vector<char> data;
    for (uint outer = 0; outer < float_data.size(); outer++)
      for (auto inner = 0; inner < sizeof(float) / sizeof(char); inner++)
        data.push_back(*(reinterpret_cast<char*>(&float_data) + inner));

args: 
attrs: 
	shape REQUIRED
	`Datatype`: `vector<int>`

The shape of the output tensor

	data_type REQUIRED
	`Datatype`: `string`

The data type of the data of output feature maps, we use FLOAT32 as the default.

	data REQUIRED
	Constant values stored in this operator, 
float-point data in vector<char>.


====================== avgpool2d ==================
op: avgpool2d
doc: 2D average-pooling.

    output[batch, oh, ow, c] =
        avg_{kw, kh} input[batch, strides[1] * oh + kh,
           strides[0] * ow + kw, c] *
(1). if pad_mode == "`FLOOR`":

    output_shape = floor((input_shape + pad - kernel) / stride) + 1
(2). if pad_mode == "`CEIL`":

    output_shape = ceil((input_shape + pad - kernel) / stride) + 1
(3). if pad_mode == "`SAME`":

    output_shape = ceil((input_shape + pad) / stride)
(4). if pad_mode == "`VALID`":

    output_shape = ceil((input_shape + pad - kernel) / stride)

args: 
	input :: FLOAT32 REQUIRED
	An input tensor with shape `[batch, in_height, in_width, in_channels]`.

attrs: 
	kernel REQUIRED
	`Datatype`: `vector<int>`

The kernel sizes of the filter. The value must be: `{kernel_width, kernel_height}`.

	stride REQUIRED
	`Datatype`: `vector<int>`

The strides of the filter. The value must be: `{stride_width, stride_height}`.

	pad_mode REQUIRED
	`Datatype`: `string`

We support 4 padding mode: FLOOR, CEIL, SAME, VALID. For example, when you parsing models from other frameworks, `caffe->"CEIL",  tensorflow->"SAME" or "VALID", pytorch->"FLOOR"(default) or "CEIL".`

	pad OPTIONAL
	`Datatype`: `vector<int>`

The padding sizes of input feature maps. The value must be `{left, right, top, bottom}`.

	global OPTIONAL
	`Datatype`: `bool`

Global pooling, if global is set to be true, the width and height of output feature maps would be {1, 1}.

	count_include_pad OPTIONAL
	`Datatype`: `bool`

if count data in the pad position for avg_pool?For example, caffe is `true`, tensorflow is `false`,pytorch uses `true` as default.

	count_include_invalid OPTIONAL
	`Datatype`: `bool`

if count data outside the padded input feature maps?For example, caffe is `false`, tf is `true`,pytorch is `true`.

====================== transposed-depthwise-conv3d-fix ==================
op: transposed-depthwise-conv3d-fix
doc: 
args: 
	input :: XINT32 REQUIRED
	An input tensor with shape `[batch, in_height, in_width, in_depth, in_channels]`.

	weights :: XINT32 REQUIRED
	A filter tensor with shape `[output_channels, kernel_height, kernel_width, kernel_depth, in_channels]`.

	bias :: XINT32 OPTIONAL
	A bias tensor with shape `[output_channels]`.

attrs: 
	kernel REQUIRED
	`Datatype`: `vector<int>`

The kernel sizes of the filter. The value must be: `{kernel_width, kernel_height}`.

	stride REQUIRED
	`Datatype`: `vector<int>`

The strides of the filter. The value must be: `{stride_width, stride_height}`.

	dilation OPTIONAL
	`Datatype`: `vector<int>`

The dilation of the filter. The value must be: `{dilation_width, dilation_height}`, The dilation in the batch or depth are 1 in default.

	pad OPTIONAL
	`Datatype`: `vector<int>`

The padding sizes of input feature maps. The value must be `{left, right, top, bottom}`.

For transposed convolutions, the padding here denotes the `{kernel_size - 1 - actual_padding}`.This is an optional attribute, when the pad_mode is SAME or VALID, you don't need to specify this attribute.

	nonlinear OPTIONAL
	`Datatype`: `string`

nonlinear type, "NONE", "RELU", "PRELU", "LEAKYRELU","RELU6","HSIGMOID","HSWISH".

====================== hard-sigmoid ==================
op: hard-sigmoid
doc: Computes the hard sigmoid function element-wise:

    f(x) = relu6(x + 3) / 6.

args: 
	input :: FLOAT32 REQUIRED
	The feature maps, can be x-dimension.

attrs: 
====================== download ==================
op: download
doc: An interface operator that holds the data achieved by a DPU-runner, and would be sent to a CPU-runner later.
args: 
	input :: XINT32 REQUIRED
	The feature maps, can be x-dimension.

attrs: 
====================== transposed-depthwise-conv2d ==================
op: transposed-depthwise-conv2d
doc: 2D depth-wise transposed convolution, our equivalent implementations::
Firstly, we dilate the input feature maps by `stride`:

    dilated_input[batch, h, w, c] =
        ((h mod stride[1] == 0) && (w mod stride[0] == 0))
        ? input[batch, h / stride[1], h / stride[0], ic]
        : 0
Secondly, we do 2D-convolution on the feature maps:

    output[batch, oh, ow, b * c] =
        sum_{kw, kh} dilated_input[batch, oh + kh, ow + kw, c] *
                     filter[b, kh, kw, c]
If pad is set:

    actual_padding[n] = kernel (h or w) - 1 - pad[n]
    padded_dilated_input[batch, h - actual_padding[2], w - actual_padding[0], c] =
        dilated_input[batch, h, w, c]
    padded_dilated_input[batch, 0 : actual_padding[2], 0 : actual_padding[0], c] = 0
    padded_dilated_input[batch, h + actual_padding[2] : h + actual_padding[2] + actual_padding[3]
                         w + actual_padding[0] : w + actual_padding[0] + actual_padding[1], c] = 0
And here is how to calculate the output shape according to the attributes:

(1). if pad_mode == "`FLOOR`":

    output_shape = (in_shape - 1) * stride + dilation * (kernel - 1) + 1 - pad
(2). if pad_mode == "`CEIL`":

    output_shape = (in_shape - 1) * stride + dilation * (kernel - 1) + 1 - pad
(3). if pad_mode == "`SAME`":

    output_shape = in_shape * stride
(4). if pad_mode == "`VALID`":

    output_shape = (in_shape - 1) * stride + kernel

args: 
	input :: FLOAT32 REQUIRED
	An input tensor with shape `[batch, in_height, in_width, in_channels]`.

	weights :: FLOAT32 REQUIRED
	A filter tensor with shape `[output_channels, kernel_height, kernel_width, in_channels]`.

	bias :: FLOAT32 OPTIONAL
	A bias tensor with shape `[output_channels]`.

attrs: 
	kernel REQUIRED
	`Datatype`: `vector<int>`

The kernel sizes of the filter. The value must be: `{kernel_width, kernel_height}`.

	stride REQUIRED
	`Datatype`: `vector<int>`

The strides of the filter. The value must be: `{stride_width, stride_height}`.

	dilation OPTIONAL
	`Datatype`: `vector<int>`

The dilation of the filter. The value must be: `{dilation_width, dilation_height}`, The dilation in the batch or depth are 1 in default.

	pad_mode REQUIRED
	`Datatype`: `string`

We support 4 padding mode: `FLOOR, CEIL, SAME, VALID`. For example, when you parsing models from other frameworks, `caffe, pytorch->"FLOOR", tensorflow->"SAME" or "VALID"`.

	pad OPTIONAL
	`Datatype`: `vector<int>`

The padding sizes of input feature maps. The value must be `{left, right, top, bottom}`.

For transposed convolutions, the padding here denotes the `{kernel_size - 1 - actual_padding}`.This is an optional attribute, when the pad_mode is SAME or VALID, you don't need to specify this attribute.

====================== const-fix ==================
op: const-fix
doc: A placeholder which stores the parameters, 
such as fixed-point weights, bias, etc.
args: 
attrs: 
	shape REQUIRED
	`Datatype`: `vector<int>`

The shape of the output tensor

	data_type REQUIRED
	`Datatype`: `string`

The data type of the data of output feature maps, we use FLOAT32 as the default.

	data REQUIRED
	Constant values stored in this operator, 
fixed-point data in vector<char>.


====================== upload ==================
op: upload
doc: An interface operator that holds the data achieved by a CPU-runner, and would be sent to a DPU-runner later.
args: 
	input :: FLOAT32 REQUIRED
	The feature maps, can be x-dimension.

attrs: 
====================== random_standard_normal ==================
op: random_standard_normal
doc: Outputs random values from a normal distribution.

And the generated values will have mean 0 and standard deviation 1.
args: 
attrs: 
	shape REQUIRED
	`Datatype`: `vector<int>`

The shape of the output tensor

	data_type REQUIRED
	`Datatype`: `string`

The data type of the data of output feature maps, we use FLOAT32 as the default.

	seed OPTIONAL
	`DataType`: `int`

Defaults to 0. If either `seed` or `seed2` are set to be non-zero, the random number generator is seeded by the given seed. Otherwise, it is seeded by a random seed.

	seed2 OPTIONAL
	`DataType`: `int`

Defaults to 0. A second seed to avoid seed collision.

====================== data-fix ==================
op: data-fix
doc: A placeholder which stores the fixed-point input data, 
data operator would always be fed by users.
args: 
attrs: 
	shape REQUIRED
	`Datatype`: `vector<int>`

The shape of the output tensor

	data_type REQUIRED
	`Datatype`: `string`

The data type of the data of output feature maps, we use FLOAT32 as the default.

====================== fix2float ==================
op: fix2float
doc: Transform the fixed value x into float output:

(1). if_signed == true:

    output = max(-pow(2, bit_width - 1),
                 min(x, pow(2, bit_width - 1) - 1)))
               * pow(2, -fix_point)
(2). if_signed == false:

    output = max(0, min(x, pow(2, bit_width) - 1)))
               * pow(2, -fix_point)

args: 
	input :: XINT32 REQUIRED
	The feature maps, can be x-dimension.

attrs: 
	fix_point REQUIRED
	`Datatype`: `int`

The fixed position of the output feature maps.

	bit_width REQUIRED
	`Datatype`: `int`

The bit width of the output feature maps.

	round_mode REQUIRED
	`Datatype`: `string`

The round mode function for transforming the float data.The round mode is one of `{STD_ROUND, DPU_ROUND, PY3_ROUND}`

(1). If the round_mode = `STD_ROUND`:

    f(x) = std::round(x)
For example, f(2.3) = 2, f(2.5) = 3, f(-2.5) = -3, f(-2.6) = -3.

(2). If the round_mode = `DPU_ROUND`:

    f(x) = ((x < 0) && (x - floor(x) == 0.5))
           ? std::ceil(x)
           : std::round(x)
For example, f(2.3) = 2, f(2.5) = 3, f(-2.5) = -2, f(-2.6) = -3.

(3). If the round_mode = `PY3_ROUND`:

Round to even.For example, f(2.3) = 2, f(2.5) = 2, f(-2.5) = -2, f(-2.6) = -3.



	if_signed REQUIRED
	`Datatype`: `bool`

If the output feature maps is signed, this attr is set to be true.

====================== div ==================
op: div
doc: We support broadcasting operations:

    "add": input[0] + input[1]
    "sub": input[0] - input[1]
    "mul": input[0] * input[1]
    "div": input[0] / input[1]
    "min": min(input[0], input[1])
    "max": max(input[0], input[1])
What is broadcasting?

When operating on two arrays, we compare their shapes element-wise. 
It starts with the trailing dimensions, and works its way forward.

Two dimensions are compatible when:

1. they are equal, or
2. one of them is 1
If these conditions are not met, a mismatch would be thrown, 
indicating that the arrays have incompatible shapes. 
The size of the resulting array is the maximum size 
along each dimension of the input arrays.
For example,

(1). bias_add, which is a channel-wise operation:

    input[0] (4d tensor): 1 x 112 x 112 x 64
    input[1] (1d tensor):                 64
    result   (4d tensor): 1 x 112 x 112 x 64
(2). element-wise add, which is an element-wise operation:

    input[0] (3d tensor): 32 x 32 x 10
    input[1] (3d tensor): 32 x 32 x 10
    result   (3d tensor): 32 x 32 x 10
(3). more examples:

    input[0] (4d tensor): 1 x 32 x 32 x 10
    input[1] (3d tensor):     32 x  1 x  1
    result   (4d tensor): 1 x 32 x 32 x 10
(4). mismatched examples:

    input[0] (4d tensor): 1 x 32 x 32 x 10
    input[1] (3d tensor):      1 x 32 x  2
    result              :         mismatch

args: 
	input :: FLOAT32 REQUIRED_AND_REPEATED
	The feature maps, can be x-dimension.

attrs: 
====================== min ==================
op: min
doc: We support broadcasting operations:

    "add": input[0] + input[1]
    "sub": input[0] - input[1]
    "mul": input[0] * input[1]
    "div": input[0] / input[1]
    "min": min(input[0], input[1])
    "max": max(input[0], input[1])
What is broadcasting?

When operating on two arrays, we compare their shapes element-wise. 
It starts with the trailing dimensions, and works its way forward.

Two dimensions are compatible when:

1. they are equal, or
2. one of them is 1
If these conditions are not met, a mismatch would be thrown, 
indicating that the arrays have incompatible shapes. 
The size of the resulting array is the maximum size 
along each dimension of the input arrays.
For example,

(1). bias_add, which is a channel-wise operation:

    input[0] (4d tensor): 1 x 112 x 112 x 64
    input[1] (1d tensor):                 64
    result   (4d tensor): 1 x 112 x 112 x 64
(2). element-wise add, which is an element-wise operation:

    input[0] (3d tensor): 32 x 32 x 10
    input[1] (3d tensor): 32 x 32 x 10
    result   (3d tensor): 32 x 32 x 10
(3). more examples:

    input[0] (4d tensor): 1 x 32 x 32 x 10
    input[1] (3d tensor):     32 x  1 x  1
    result   (4d tensor): 1 x 32 x 32 x 10
(4). mismatched examples:

    input[0] (4d tensor): 1 x 32 x 32 x 10
    input[1] (3d tensor):      1 x 32 x  2
    result              :         mismatch

args: 
	input :: FLOAT32 REQUIRED_AND_REPEATED
	The feature maps, can be x-dimension.

attrs: 
====================== fix ==================
op: fix
doc: fix operator transforms float-point value into fixed-point value into float-point format.

(1). Firstly, we transform the float input feature map x into fixed value:

    fixed_value = round(x * pow(2, fix_point))
and then

(2) transform the fixed value into float-point format:

-> if_signed == true:

    output = max(-pow(2, bit_width - 1),
                 min(fixed_value, pow(2, bit_width - 1) - 1)))
               * pow(2, -fix_point)
-> if_signed == false:

    output = max(0, min(fixed_value, pow(2, bit_width) - 1)))
               * pow(2, -fix_point)

args: 
	input :: FLOAT32 REQUIRED
	The feature maps, can be x-dimension.

attrs: 
	fix_point REQUIRED
	`Datatype`: `int`

The fixed position of the output feature maps.

	bit_width REQUIRED
	`Datatype`: `int`

The bit width of the output feature maps.

	round_mode REQUIRED
	`Datatype`: `string`

The round mode function for transforming the float data.The round mode is one of `{STD_ROUND, DPU_ROUND, PY3_ROUND}`

(1). If the round_mode = `STD_ROUND`:

    f(x) = std::round(x)
For example, f(2.3) = 2, f(2.5) = 3, f(-2.5) = -3, f(-2.6) = -3.

(2). If the round_mode = `DPU_ROUND`:

    f(x) = ((x < 0) && (x - floor(x) == 0.5))
           ? std::ceil(x)
           : std::round(x)
For example, f(2.3) = 2, f(2.5) = 3, f(-2.5) = -2, f(-2.6) = -3.

(3). If the round_mode = `PY3_ROUND`:

Round to even.For example, f(2.3) = 2, f(2.5) = 2, f(-2.5) = -2, f(-2.6) = -3.



	if_signed REQUIRED
	`Datatype`: `bool`

If the output feature maps is signed, this attr is set to be true.

====================== float2fix ==================
op: float2fix
doc: Transform the float value x into fixed value:

    f(x) = round(x * pow(2, fix_point))
The round function is determined by the round_mode.

(1). if_signed == true:

    output = max(-pow(2, bit_width - 1),
                 min(f(x), pow(2, bit_width - 1) - 1)))
(2). if_signed == false:

    output = max(0, min(f(x), pow(2, bit_width) - 1)))

args: 
	input :: FLOAT32 REQUIRED
	The feature maps, can be x-dimension.

attrs: 
	fix_point REQUIRED
	`Datatype`: `int`

The fixed position of the output feature maps.

	bit_width REQUIRED
	`Datatype`: `int`

The bit width of the output feature maps.

	round_mode REQUIRED
	`Datatype`: `string`

The round mode function for transforming the float data.The round mode is one of `{STD_ROUND, DPU_ROUND, PY3_ROUND}`

(1). If the round_mode = `STD_ROUND`:

    f(x) = std::round(x)
For example, f(2.3) = 2, f(2.5) = 3, f(-2.5) = -3, f(-2.6) = -3.

(2). If the round_mode = `DPU_ROUND`:

    f(x) = ((x < 0) && (x - floor(x) == 0.5))
           ? std::ceil(x)
           : std::round(x)
For example, f(2.3) = 2, f(2.5) = 3, f(-2.5) = -2, f(-2.6) = -3.

(3). If the round_mode = `PY3_ROUND`:

Round to even.For example, f(2.3) = 2, f(2.5) = 2, f(-2.5) = -2, f(-2.6) = -3.



	if_signed REQUIRED
	`Datatype`: `bool`

If the output feature maps is signed, this attr is set to be true.

====================== transposed-conv3d-fix ==================
op: transposed-conv3d-fix
doc: 
args: 
	input :: XINT32 REQUIRED
	An input tensor with shape `[batch, in_height, in_width, in_depth, in_channels]`.

	weights :: XINT32 REQUIRED
	A filter tensor with shape `[output_channels, kernel_height, kernel_width, kernel_depth, in_channels]`.

	bias :: XINT32 OPTIONAL
	A bias tensor with shape `[output_channels]`.

attrs: 
	kernel REQUIRED
	`Datatype`: `vector<int>`

The kernel sizes of the filter. The value must be: `{kernel_width, kernel_height}`.

	stride REQUIRED
	`Datatype`: `vector<int>`

The strides of the filter. The value must be: `{stride_width, stride_height}`.

	dilation OPTIONAL
	`Datatype`: `vector<int>`

The dilation of the filter. The value must be: `{dilation_width, dilation_height}`, The dilation in the batch or depth are 1 in default.

	pad OPTIONAL
	`Datatype`: `vector<int>`

The padding sizes of input feature maps. The value must be `{left, right, top, bottom}`.

For transposed convolutions, the padding here denotes the `{kernel_size - 1 - actual_padding}`.This is an optional attribute, when the pad_mode is SAME or VALID, you don't need to specify this attribute.

	nonlinear OPTIONAL
	`Datatype`: `string`

nonlinear type, "NONE", "RELU", "PRELU", "LEAKYRELU","RELU6","HSIGMOID","HSWISH".

====================== conv2d ==================
op: conv2d
doc: 2D convolution.

    output[batch, oh, ow, oc] =
        sum_{kw, kh, ic} input[batch, strides[1] * oh + kh, strides[0] * ow + kw, ic] *
                        filter[oc, kh, kw, ic]
(1). if pad_mode == "`FLOOR`":

    output_shape = floor((input_shape + pad - (kernel - 1) * dilation + 1) / stride) + 1
(2). if pad_mode == "`CEIL`":

    output_shape = ceil((input_shape + pad - (kernel - 1) * dilation + 1) / stride) + 1
(3). if pad_mode == "`SAME`":

    output_shape = ceil((input_shape + pad) / stride)
(4). if pad_mode == "`VALID`":

    output_shape = ceil((input_shape + pad - (kernel - 1) * dilation) / stride)

args: 
	input :: FLOAT32 REQUIRED
	An input tensor with shape `[batch, in_height, in_width, in_channels]`.

	weights :: FLOAT32 REQUIRED
	A filter tensor with shape `[output_channels, kernel_height, kernel_width, in_channels]`.

	bias :: FLOAT32 OPTIONAL
	A bias tensor with shape `[output_channels]`.

attrs: 
	kernel REQUIRED
	`Datatype`: `vector<int>`

The kernel sizes of the filter. The value must be: `{kernel_width, kernel_height}`.

	stride REQUIRED
	`Datatype`: `vector<int>`

The strides of the filter. The value must be: `{stride_width, stride_height}`.

	dilation OPTIONAL
	`Datatype`: `vector<int>`

The dilation of the filter. The value must be: `{dilation_width, dilation_height}`, The dilation in the batch or depth are 1 in default.

	pad_mode REQUIRED
	`Datatype`: `string`

We support 4 padding mode: `FLOOR, CEIL, SAME, VALID`. For example, when you parsing models from other frameworks, `caffe, pytorch->"FLOOR", tensorflow->"SAME" or "VALID"`.

	pad OPTIONAL
	`Datatype`: `vector<int>`

The padding sizes of input feature maps. The value must be `{left, right, top, bottom}`.

For transposed convolutions, the padding here denotes the `{kernel_size - 1 - actual_padding}`.This is an optional attribute, when the pad_mode is SAME or VALID, you don't need to specify this attribute.

====================== depthwise-conv2d ==================
op: depthwise-conv2d
doc: Depth-wise 2D convolution.

    output[batch, oh, ow, b * c] =
        sum_{kw, kh} input[batch, strides[1] * oh + kh, strides[0] * ow + kw, c] *
                        filter[b, kh, kw, c]
(1). if pad_mode == "`FLOOR`":

    output_shape = floor((input_shape + pad - (kernel - 1) * dilation + 1) / stride) + 1
(2). if pad_mode == "`CEIL`":

    output_shape = ceil((input_shape + pad - (kernel - 1) * dilation + 1) / stride) + 1
(3). if pad_mode == "`SAME`":

    output_shape = ceil((input_shape + pad) / stride)
(4). if pad_mode == "`VALID`":

    output_shape = ceil((input_shape + pad - (kernel - 1) * dilation) / stride)
For example, in Tensorflow, tf.nn.depthwise_conv2d is:

    output[b, i, j, k * channel_multiplier + q] = sum_{di, dj}
        filter[di, dj, k, q] * input[b, stride[1] * i + rate[0] * di,
                                        stride[2] * j + rate[1] * dk, k]
Given a 4D input tensor ('NHWC' or 'NCHW' data formats) and a filter tensor of shape [filter_height, filter_width, in_channels, channel_multiplier]if we want to transform tf.nn.depthwise_conv2d into XIR depthwise-conv2d, then in XIR

    output[b, i, j, k * channel_multiplier + q] = sum_{di, dj}
        filter[q, di, dj, k] * input[b, stride[1] * i + rate[0] * di,
                                        stride[0] * j + rate[1] * dk, k]
In another example, for convolution in caffe, if the attribute `group` euqals to the input channels of the input feature maps, then this convolutioncan be transformed into a XIR depthwise-conv2d.
args: 
	input :: FLOAT32 REQUIRED
	An input tensor with shape `[batch, in_height, in_width, in_channels]`.

	weights :: FLOAT32 REQUIRED
	A filter tensor with shape `[output_channels, kernel_height, kernel_width, in_channels]`.

	bias :: FLOAT32 OPTIONAL
	A bias tensor with shape `[output_channels]`.

attrs: 
	kernel REQUIRED
	`Datatype`: `vector<int>`

The kernel sizes of the filter. The value must be: `{kernel_width, kernel_height}`.

	stride REQUIRED
	`Datatype`: `vector<int>`

The strides of the filter. The value must be: `{stride_width, stride_height}`.

	dilation OPTIONAL
	`Datatype`: `vector<int>`

The dilation of the filter. The value must be: `{dilation_width, dilation_height}`, The dilation in the batch or depth are 1 in default.

	pad_mode REQUIRED
	`Datatype`: `string`

We support 4 padding mode: `FLOOR, CEIL, SAME, VALID`. For example, when you parsing models from other frameworks, `caffe, pytorch->"FLOOR", tensorflow->"SAME" or "VALID"`.

	pad OPTIONAL
	`Datatype`: `vector<int>`

The padding sizes of input feature maps. The value must be `{left, right, top, bottom}`.

For transposed convolutions, the padding here denotes the `{kernel_size - 1 - actual_padding}`.This is an optional attribute, when the pad_mode is SAME or VALID, you don't need to specify this attribute.

====================== depthwise-conv2d-fix ==================
op: depthwise-conv2d-fix
doc: 
args: 
	input :: XINT32 REQUIRED
	An input tensor with shape `[batch, in_height, in_width, in_channels]`.

	weights :: XINT32 REQUIRED
	A filter tensor with shape `[output_channels, kernel_height, kernel_width, in_channels]`.

	bias :: XINT32 OPTIONAL
	A bias tensor with shape `[output_channels]`.

attrs: 
	kernel REQUIRED
	`Datatype`: `vector<int>`

The kernel sizes of the filter. The value must be: `{kernel_width, kernel_height}`.

	stride REQUIRED
	`Datatype`: `vector<int>`

The strides of the filter. The value must be: `{stride_width, stride_height}`.

	dilation OPTIONAL
	`Datatype`: `vector<int>`

The dilation of the filter. The value must be: `{dilation_width, dilation_height}`, The dilation in the batch or depth are 1 in default.

	pad OPTIONAL
	`Datatype`: `vector<int>`

The padding sizes of input feature maps. The value must be `{left, right, top, bottom}`.

For transposed convolutions, the padding here denotes the `{kernel_size - 1 - actual_padding}`.

	nonlinear OPTIONAL
	`Datatype`: `string`

nonlinear type, "NONE", "RELU", "PRELU", "LEAKYRELU","RELU6","HSIGMOID","HSWISH".

====================== add ==================
op: add
doc: We support broadcasting operations:

    "add": input[0] + input[1]
    "sub": input[0] - input[1]
    "mul": input[0] * input[1]
    "div": input[0] / input[1]
    "min": min(input[0], input[1])
    "max": max(input[0], input[1])
What is broadcasting?

When operating on two arrays, we compare their shapes element-wise. 
It starts with the trailing dimensions, and works its way forward.

Two dimensions are compatible when:

1. they are equal, or
2. one of them is 1
If these conditions are not met, a mismatch would be thrown, 
indicating that the arrays have incompatible shapes. 
The size of the resulting array is the maximum size 
along each dimension of the input arrays.
For example,

(1). bias_add, which is a channel-wise operation:

    input[0] (4d tensor): 1 x 112 x 112 x 64
    input[1] (1d tensor):                 64
    result   (4d tensor): 1 x 112 x 112 x 64
(2). element-wise add, which is an element-wise operation:

    input[0] (3d tensor): 32 x 32 x 10
    input[1] (3d tensor): 32 x 32 x 10
    result   (3d tensor): 32 x 32 x 10
(3). more examples:

    input[0] (4d tensor): 1 x 32 x 32 x 10
    input[1] (3d tensor):     32 x  1 x  1
    result   (4d tensor): 1 x 32 x 32 x 10
(4). mismatched examples:

    input[0] (4d tensor): 1 x 32 x 32 x 10
    input[1] (3d tensor):      1 x 32 x  2
    result              :         mismatch

args: 
	input :: FLOAT32 REQUIRED_AND_REPEATED
	The feature maps, can be x-dimension.

attrs: 
====================== maxpool2d ==================
op: maxpool2d
doc: 2D max-pooling.

    output[batch, oh, ow, c] =
        max_{kw, kh} input[batch, strides[1] * oh + kh,
           strides[0] * ow + kw, c] *
(1). if pad_mode == "`FLOOR`":

    output_shape = floor((input_shape + pad - kernel) / stride) + 1
(2). if pad_mode == "`CEIL`":

    output_shape = ceil((input_shape + pad - kernel) / stride) + 1
(3). if pad_mode == "`SAME`":

    output_shape = ceil((input_shape + pad) / stride)
(4). if pad_mode == "`VALID`":

    output_shape = ceil((input_shape + pad - kernel) / stride)

args: 
	input :: FLOAT32 REQUIRED
	An input tensor with shape `[batch, in_height, in_width, in_channels]`.

attrs: 
	kernel REQUIRED
	`Datatype`: `vector<int>`

The kernel sizes of the filter. The value must be: `{kernel_width, kernel_height}`.

	stride REQUIRED
	`Datatype`: `vector<int>`

The strides of the filter. The value must be: `{stride_width, stride_height}`.

	pad_mode REQUIRED
	`Datatype`: `string`

We support 4 padding mode: FLOOR, CEIL, SAME, VALID. For example, when you parsing models from other frameworks, `caffe->"CEIL",  tensorflow->"SAME" or "VALID", pytorch->"FLOOR"(default) or "CEIL".`

	pad OPTIONAL
	`Datatype`: `vector<int>`

The padding sizes of input feature maps. The value must be `{left, right, top, bottom}`.

	global OPTIONAL
	`Datatype`: `bool`

Global pooling, if global is set to be true, the width and height of output feature maps would be {1, 1}.

====================== transposed-conv2d ==================
op: transposed-conv2d
doc: 2D transposed convolution, our equivalent implementations:
Firstly, we dilate the input feature maps by `stride`:

    dilated_input[batch, h, w, c] =
        ((h mod stride[1] == 0) && (w mod stride[0] == 0))
        ? input[batch, h / stride[1], h / stride[0], ic]
        : 0
Secondly, we do 2D-convolution on the feature maps:

    output[batch, oh, ow, oc] =
        sum_{kw, kh, ic} dilated_input[batch, oh + kh, ow + kw, ic] *
                        filter[oc, kh, kw, ic]
If pad is set:

    actual_padding[n] = kernel (h or w) - 1 - pad[n]
    padded_dilated_input[batch, h - actual_padding[2], w - actual_padding[0], c] =
        dilated_input[batch, h, w, c]
    padded_dilated_input[batch, 0 : actual_padding[2], 0 : actual_padding[0], c] = 0
    padded_dilated_input[batch, h + actual_padding[2] : h + actual_padding[2] + actual_padding[3]
                         w + actual_padding[0] : w + actual_padding[0] + actual_padding[1], c] = 0
And here is how to calculate the output shape according to the attributes:

(1). if pad_mode == "`FLOOR`":

    output_shape = (in_shape - 1) * stride + dilation * (kernel - 1) + 1 - pad
(2). if pad_mode == "`CEIL`":

    output_shape = (in_shape - 1) * stride + dilation * (kernel - 1) + 1 - pad
(3). if pad_mode == "`SAME`":

    output_shape = in_shape * stride
(4). if pad_mode == "`VALID`":

    output_shape = (in_shape - 1) * stride + kernel
For example, to transform a conv2d_transpose or Conv2DBackpropInput in Tensorflow into XIR:
we only need to change the filter in tensorflow into XIR format.

(1). flip the filter along the dimension of width and height,

(2). transpose the filter into `{oc, h, w, ic}`, ic equals the channel of input feature maps and oc equals to the channel of output feature maps.
args: 
	input :: FLOAT32 REQUIRED
	An input tensor with shape `[batch, in_height, in_width, in_channels]`.

	weights :: FLOAT32 REQUIRED
	A filter tensor with shape `[output_channels, kernel_height, kernel_width, in_channels]`.

	bias :: FLOAT32 OPTIONAL
	A bias tensor with shape `[output_channels]`.

attrs: 
	kernel REQUIRED
	`Datatype`: `vector<int>`

The kernel sizes of the filter. The value must be: `{kernel_width, kernel_height}`.

	stride REQUIRED
	`Datatype`: `vector<int>`

The strides of the filter. The value must be: `{stride_width, stride_height}`.

	dilation OPTIONAL
	`Datatype`: `vector<int>`

The dilation of the filter. The value must be: `{dilation_width, dilation_height}`, The dilation in the batch or depth are 1 in default.

	pad_mode REQUIRED
	`Datatype`: `string`

We support 4 padding mode: `FLOOR, CEIL, SAME, VALID`. For example, when you parsing models from other frameworks, `caffe, pytorch->"FLOOR", tensorflow->"SAME" or "VALID"`.

	pad OPTIONAL
	`Datatype`: `vector<int>`

The padding sizes of input feature maps. The value must be `{left, right, top, bottom}`.

For transposed convolutions, the padding here denotes the `{kernel_size - 1 - actual_padding}`.This is an optional attribute, when the pad_mode is SAME or VALID, you don't need to specify this attribute.

====================== elu ==================
op: elu
doc: Computes the elu function element-wise:

    f(x) = x if x > 0.
    f(x) = alpha * (exp(x) - 1) if x <= 0.

args: 
	input :: FLOAT32 REQUIRED
	The feature maps, can be x-dimension.

attrs: 
	alpha OPTIONAL
	`Datatype`: `float`

Slope of the activation function at x <= 0.

====================== sub ==================
op: sub
doc: We support broadcasting operations:

    "add": input[0] + input[1]
    "sub": input[0] - input[1]
    "mul": input[0] * input[1]
    "div": input[0] / input[1]
    "min": min(input[0], input[1])
    "max": max(input[0], input[1])
What is broadcasting?

When operating on two arrays, we compare their shapes element-wise. 
It starts with the trailing dimensions, and works its way forward.

Two dimensions are compatible when:

1. they are equal, or
2. one of them is 1
If these conditions are not met, a mismatch would be thrown, 
indicating that the arrays have incompatible shapes. 
The size of the resulting array is the maximum size 
along each dimension of the input arrays.
For example,

(1). bias_add, which is a channel-wise operation:

    input[0] (4d tensor): 1 x 112 x 112 x 64
    input[1] (1d tensor):                 64
    result   (4d tensor): 1 x 112 x 112 x 64
(2). element-wise add, which is an element-wise operation:

    input[0] (3d tensor): 32 x 32 x 10
    input[1] (3d tensor): 32 x 32 x 10
    result   (3d tensor): 32 x 32 x 10
(3). more examples:

    input[0] (4d tensor): 1 x 32 x 32 x 10
    input[1] (3d tensor):     32 x  1 x  1
    result   (4d tensor): 1 x 32 x 32 x 10
(4). mismatched examples:

    input[0] (4d tensor): 1 x 32 x 32 x 10
    input[1] (3d tensor):      1 x 32 x  2
    result              :         mismatch

args: 
	input :: FLOAT32 REQUIRED_AND_REPEATED
	The feature maps, can be x-dimension.

attrs: 
====================== conv3d ==================
op: conv3d
doc: 3D convolution.


args: 
	input :: FLOAT32 REQUIRED
	An input tensor with shape `[batch, in_height, in_width, depth, in_channels]`.

	weights :: FLOAT32 REQUIRED
	A filter tensor with shape `[output_channels, kernel_height, kernel_width, kernel_depth, in_channels]`.

	bias :: FLOAT32 OPTIONAL
	A bias tensor with shape `[output_channels]`.

attrs: 
	kernel REQUIRED
	`Datatype`: `vector<int>`

The kernel sizes of the filter. The value must be: `{kernel_width, kernel_height, kernel_depth}`.

	stride REQUIRED
	`Datatype`: `vector<int>`

The strides of the filter. The value must be: `{stride_width, stride_height, stride_depth}`.

	dilation OPTIONAL
	`Datatype`: `vector<int>`

The dilation of the filter. The value must be: `{dilation_width, dilation_height, dilation_depth}`, The dilation in the batch or depth are 1 in default.

	pad_mode REQUIRED
	`Datatype`: `string`

We support 4 padding mode: `FLOOR, CEIL, SAME, VALID`. For example, when you parsing models from other frameworks, `caffe, pytorch->"FLOOR", tensorflow->"SAME" or "VALID"`.

	pad OPTIONAL
	`Datatype`: `vector<int>`

The padding sizes of input feature maps. The value must be `{left, right, top, bottom, near, far}`.

For transposed convolutions, the padding here denotes the `{kernel_size - 1 - actual_padding}`.This is an optional attribute, when the pad_mode is SAME or VALID, you don't need to specify this attribute.

====================== depthwise-conv3d ==================
op: depthwise-conv3d
doc: Depth-wise 3D convolution.


args: 
	input :: FLOAT32 REQUIRED
	An input tensor with shape `[batch, in_height, in_width, depth, in_channels]`.

	weights :: FLOAT32 REQUIRED
	A filter tensor with shape `[output_channels, kernel_height, kernel_width, kernel_depth, in_channels]`.

	bias :: FLOAT32 OPTIONAL
	A bias tensor with shape `[output_channels]`.

attrs: 
	kernel REQUIRED
	`Datatype`: `vector<int>`

The kernel sizes of the filter. The value must be: `{kernel_width, kernel_height, kernel_depth}`.

	stride REQUIRED
	`Datatype`: `vector<int>`

The strides of the filter. The value must be: `{stride_width, stride_height, stride_depth}`.

	dilation OPTIONAL
	`Datatype`: `vector<int>`

The dilation of the filter. The value must be: `{dilation_width, dilation_height, dilation_depth}`, The dilation in the batch or depth are 1 in default.

	pad_mode REQUIRED
	`Datatype`: `string`

We support 4 padding mode: `FLOOR, CEIL, SAME, VALID`. For example, when you parsing models from other frameworks, `caffe, pytorch->"FLOOR", tensorflow->"SAME" or "VALID"`.

	pad OPTIONAL
	`Datatype`: `vector<int>`

The padding sizes of input feature maps. The value must be `{left, right, top, bottom, near, far}`.

For transposed convolutions, the padding here denotes the `{kernel_size - 1 - actual_padding}`.This is an optional attribute, when the pad_mode is SAME or VALID, you don't need to specify this attribute.

====================== celu ==================
op: celu
doc: Computes the celu function element-wise:

    f(x) = max(0, x) + min(0, alpha * (exp(x / alpha) - 1)).

args: 
	input :: FLOAT32 REQUIRED
	The feature maps, can be x-dimension.

attrs: 
	alpha OPTIONAL
	`Datatype`: `float`

Slope of the activation function.

====================== shape ==================
op: shape
doc: Return the shape of the input feature maps.
args: 
	input :: FLOAT32 REQUIRED
	The feature maps, can be x-dimension.

attrs: 
====================== pool-fix ==================
op: pool-fix
doc: 
args: 
	input :: XINT32 REQUIRED
	An input tensor with shape `[batch, in_height, in_width, in_channels]`.

attrs: 
	kernel REQUIRED
	`Datatype`: `vector<int>`

The kernel sizes of the filter. The value must be: `{kernel_width, kernel_height}`.

	stride REQUIRED
	`Datatype`: `vector<int>`

The strides of the filter. The value must be: `{stride_width, stride_height}`.

	pad OPTIONAL
	`Datatype`: `vector<int>`

The padding sizes of input feature maps. The value must be `{left, right, top, bottom}`. This is an optional attribute, when the pad_mode is SAME or VALID, you don't need to specify this attribute.

	type REQUIRED
	`Datatype`: `string`

Dpu pooling type, "MAX", "AVG".

====================== transposed-conv3d ==================
op: transposed-conv3d
doc: Transposed 3D convolution.


args: 
	input :: FLOAT32 REQUIRED
	An input tensor with shape `[batch, in_height, in_width, depth, in_channels]`.

	weights :: FLOAT32 REQUIRED
	A filter tensor with shape `[output_channels, kernel_height, kernel_width, kernel_depth, in_channels]`.

	bias :: FLOAT32 OPTIONAL
	A bias tensor with shape `[output_channels]`.

attrs: 
	kernel REQUIRED
	`Datatype`: `vector<int>`

The kernel sizes of the filter. The value must be: `{kernel_width, kernel_height, kernel_depth}`.

	stride REQUIRED
	`Datatype`: `vector<int>`

The strides of the filter. The value must be: `{stride_width, stride_height, stride_depth}`.

	dilation OPTIONAL
	`Datatype`: `vector<int>`

The dilation of the filter. The value must be: `{dilation_width, dilation_height, dilation_depth}`, The dilation in the batch or depth are 1 in default.

	pad_mode REQUIRED
	`Datatype`: `string`

We support 4 padding mode: `FLOOR, CEIL, SAME, VALID`. For example, when you parsing models from other frameworks, `caffe, pytorch->"FLOOR", tensorflow->"SAME" or "VALID"`.

	pad OPTIONAL
	`Datatype`: `vector<int>`

The padding sizes of input feature maps. The value must be `{left, right, top, bottom, near, far}`.

For transposed convolutions, the padding here denotes the `{kernel_size - 1 - actual_padding}`.This is an optional attribute, when the pad_mode is SAME or VALID, you don't need to specify this attribute.

====================== gelu ==================
op: gelu
doc: Computes the gelu function element-wise:

    f(x) = x * 1 / 2 * (1 + erf(x / sqrt(2))).

args: 
	input :: FLOAT32 REQUIRED
	The feature maps, can be x-dimension.

attrs: 
====================== max ==================
op: max
doc: We support broadcasting operations:

    "add": input[0] + input[1]
    "sub": input[0] - input[1]
    "mul": input[0] * input[1]
    "div": input[0] / input[1]
    "min": min(input[0], input[1])
    "max": max(input[0], input[1])
What is broadcasting?

When operating on two arrays, we compare their shapes element-wise. 
It starts with the trailing dimensions, and works its way forward.

Two dimensions are compatible when:

1. they are equal, or
2. one of them is 1
If these conditions are not met, a mismatch would be thrown, 
indicating that the arrays have incompatible shapes. 
The size of the resulting array is the maximum size 
along each dimension of the input arrays.
For example,

(1). bias_add, which is a channel-wise operation:

    input[0] (4d tensor): 1 x 112 x 112 x 64
    input[1] (1d tensor):                 64
    result   (4d tensor): 1 x 112 x 112 x 64
(2). element-wise add, which is an element-wise operation:

    input[0] (3d tensor): 32 x 32 x 10
    input[1] (3d tensor): 32 x 32 x 10
    result   (3d tensor): 32 x 32 x 10
(3). more examples:

    input[0] (4d tensor): 1 x 32 x 32 x 10
    input[1] (3d tensor):     32 x  1 x  1
    result   (4d tensor): 1 x 32 x 32 x 10
(4). mismatched examples:

    input[0] (4d tensor): 1 x 32 x 32 x 10
    input[1] (3d tensor):      1 x 32 x  2
    result              :         mismatch

args: 
	input :: FLOAT32 REQUIRED_AND_REPEATED
	The feature maps, can be x-dimension.

attrs: 
====================== relu6 ==================
op: relu6
doc: Computes the relu6 function element-wise:

    f(x) = min(max(x, 0), 6).

args: 
	input :: FLOAT32 REQUIRED
	The feature maps, can be x-dimension.

attrs: 
====================== neg ==================
op: neg
doc: This function computes the numerical negative value element-wise.

    f(x) = -x

args: 
	input :: FLOAT32 REQUIRED
	The feature maps, can be x-dimension.

attrs: 
====================== depthwise-fix ==================
op: depthwise-fix
doc: 
args: 
	input :: XINT32 REQUIRED_AND_REPEATED
	The feature maps, can be x-dimension. depthwise-fix operator implements channel-wise operations.

attrs: 
	type OPTIONAL
	`Datatype`: `string`

depthwise type, "ADD", "MUL". Default is "ADD"

====================== priorbox ==================
op: priorbox
doc: 
args: 
	input :: FLOAT32 REQUIRED_AND_REPEATED
	`[batch, in_height, in_width, in_channels]`.

attrs: 
	min_sizes REQUIRED
	`Datatype`: `vector<float>`

minimum box size (in pixels)

	max_sizes OPTIONAL
	`Datatype`: `vector<float>`

maximum box size (in pixels)

	aspect_ratio OPTIONAL
	`Datatype`: `vector<float>`

various of aspect ratios

	flip REQUIRED
	`Datatype`: `bool`

if true, will flip each aspect ratio, default True

	clip REQUIRED
	`Datatype`: `bool`

if true, will clip the prior so that it is within [0, 1].

	variance REQUIRED
	`Datatype`: `vector<float>`

variance for adjusting the prior bboxes

	step REQUIRED
	`Datatype`: `vector<float>`

step size

	offset REQUIRED
	`Datatype`: `vector<float>`

offset to the top left corner of each cell.

====================== inner-product ==================
op: inner-product
doc: Do inner-product for the input feature maps.

For example, the shape of the input is [n, a, b, c], axis = 1, Firstly, flatten the input feature maps starting from the `axis` dimension to the end. the input would be reshaped to [n, a * b * c].

Secondly, the weights would be reshaped to [k, a * b * c], 

Thirdly, the inner-product would be implemented:

    output[n, k] = sum_{i} input(n, i) * weights(k, i)
The number of bias equals to k.
args: 
	input :: FLOAT32 REQUIRED
	The feature maps, can be x-dimension.

	weights :: FLOAT32 REQUIRED
	The feature maps, can be x-dimension.

	bias :: FLOAT32 OPTIONAL
	1-dimension, OC

attrs: 
	axis REQUIRED
	`Datatype`: `int`

[axis:-1] for flatten

====================== sigmoid ==================
op: sigmoid
doc: Computes the sigmoid function element-wise:

    f(x) = 1 / (1 + exp(-x)).

args: 
	input :: FLOAT32 REQUIRED
	The feature maps, can be x-dimension.

attrs: 
====================== pad ==================
op: pad
doc: For example,

if the mode = "CONSTANT"

    input = [[1, 2],
             [3, 4]]
    paddings = [0, 1, 1, 0]
    output = [[0, 1, 2],
              [0, 3, 4],
              [0, 0, 0]]
if the mode = "REFLECT"

    input = [[1, 2],
             [3, 4]]
    paddings = [0, 1, 1, 0]
    output = [[2, 1, 2],
              [4, 3, 4],
              [2, 1, 2]]
if the mode = "SYMMETRIC"

    input = [[1, 2],
             [3, 4]]
    paddings = [0, 1, 1, 0]
    output = [[1, 1, 2],
              [3, 3, 4],
              [3, 3, 4]]

args: 
	input :: FLOAT32 REQUIRED
	The feature maps, can be x-dimension.

attrs: 
	paddings REQUIRED
	`Datatype`: `vector<int>`

pad along different dimensions, the number of value in paddings should be 2 times the number of dimensions of input feature maps.The n-th dimension of the output feature maps equals to:

    (n-th dim) out =
        paddings[2n] + (n-th dim) in + paddings[2n + 1]

	mode REQUIRED
	`Datatype`: `string`

`CONSTANT`,`REFLECT` or `SYMMETRIC`

	constant_values OPTIONAL
	`Datatype`: `vector<float>`

the value set into the padded locations, 2 * len(paddings)

====================== upsample-fix ==================
op: upsample-fix
doc: 
args: 
	input :: XINT32 REQUIRED
	The feature maps, can be x-dimension.

	size :: INT32 OPTIONAL
	Constant values denotes the shape of the output feature maps.

attrs: 
	mode REQUIRED
	`Datatype`: `string`

NEAREST, BILINEAR or TRILINEAR

	align_corners OPTIONAL
	`Datatype`: `bool`

If true, preserving the values at the corner pixels. Defaults to false.

	half_pixel_centers OPTIONAL
	`Datatype`: `bool`

If true, use half-pixel as centers.

	scale REQUIRED
	`DataType` : `std::vector<float>` {scale_w, scale_h}

====================== swish ==================
op: swish
doc: Computes the swish function element-wise:

    f(x) = x * sigmoid(x).

args: 
	input :: FLOAT32 REQUIRED
	The feature maps, can be x-dimension.

attrs: 
====================== identity ==================
op: identity
doc: An interface operator that holds the data. Do nothing here.
args: 
	input :: XINT32 REQUIRED
	The feature maps, can be x-dimension.

attrs: 
====================== tanh ==================
op: tanh
doc: Computes the tanh function element-wise:

    f(x) = tanh(x).

args: 
	input :: FLOAT32 REQUIRED
	The feature maps, can be x-dimension.

attrs: 
====================== hard-sigmoid-fix ==================
op: hard-sigmoid-fix
doc: Computes the hard sigmoid function element-wise:

    f(x) = relu6(x + 3) * 2731 / 2 ^ 14.

args: 
	input :: FLOAT32 REQUIRED
	The feature maps, can be x-dimension.

attrs: 
====================== hard-tanh ==================
op: hard-tanh
doc: Computes the hard tanh function element-wise:

    f(x) = clip(x, -1, 1).

args: 
	input :: FLOAT32 REQUIRED
	The feature maps, can be x-dimension.

attrs: 
====================== threshold ==================
op: threshold
doc: Threshold operator is used to transform fixed-point values 
to fixed-point values of different bit width.

    24 bit threshold = 13-bit base + 10-bit delta + 1-bit signal.
base is a channel-wise parameter, an int_13 number.
11 bit interger and 2 bit decimal.

delta is a channel-wise parameter, an uint_10 number.
8 bit interger and 2 bit decimal.

The output can be calculated by this function:

    base + out * delta <= in < base + (out + 1) * delta
In addition, signal indicates whether actual step is a positive number.
0 indicates positive, 1 is negative.

args: 
	input :: XINT32 REQUIRED
	The feature maps, can be x-dimension.

	threshold :: XINT32 REQUIRED
	1-dimension, 24-bit XINT

attrs: 
====================== reduction_mean ==================
op: reduction_mean
doc: Implement the mean along each of the axis dimensions.
args: 
	input :: FLOAT32 REQUIRED
	The feature maps, can be x-dimension.

attrs: 
	axis REQUIRED
	`Datatype`: `vector<int>`

The dimensions to reduce.

	keep_dims REQUIRED
	`Datatype`: `bool`

specify whether the reduced dimension is kept or not.

====================== gstiling ==================
op: gstiling
doc: 
args: 
	input :: FLOAT32 REQUIRED
	The feature maps, can be x-dimension.

attrs: 
	reverse REQUIRED
	`Datatype`: `bool`

if reverse

	stride REQUIRED
	`Datatype`: `int`

stride for feature maps

====================== mul ==================
op: mul
doc: We support broadcasting operations:

    "add": input[0] + input[1]
    "sub": input[0] - input[1]
    "mul": input[0] * input[1]
    "div": input[0] / input[1]
    "min": min(input[0], input[1])
    "max": max(input[0], input[1])
What is broadcasting?

When operating on two arrays, we compare their shapes element-wise. 
It starts with the trailing dimensions, and works its way forward.

Two dimensions are compatible when:

1. they are equal, or
2. one of them is 1
If these conditions are not met, a mismatch would be thrown, 
indicating that the arrays have incompatible shapes. 
The size of the resulting array is the maximum size 
along each dimension of the input arrays.
For example,

(1). bias_add, which is a channel-wise operation:

    input[0] (4d tensor): 1 x 112 x 112 x 64
    input[1] (1d tensor):                 64
    result   (4d tensor): 1 x 112 x 112 x 64
(2). element-wise add, which is an element-wise operation:

    input[0] (3d tensor): 32 x 32 x 10
    input[1] (3d tensor): 32 x 32 x 10
    result   (3d tensor): 32 x 32 x 10
(3). more examples:

    input[0] (4d tensor): 1 x 32 x 32 x 10
    input[1] (3d tensor):     32 x  1 x  1
    result   (4d tensor): 1 x 32 x 32 x 10
(4). mismatched examples:

    input[0] (4d tensor): 1 x 32 x 32 x 10
    input[1] (3d tensor):      1 x 32 x  2
    result              :         mismatch

args: 
	input :: FLOAT32 REQUIRED_AND_REPEATED
	The feature maps, can be x-dimension.

attrs: 
====================== hard-swish ==================
op: hard-swish
doc: Computes the hard swish function element-wise:

    f(x) = x * relu6(x + 3) / 6.

args: 
	input :: FLOAT32 REQUIRED
	The feature maps, can be x-dimension.

attrs: 
====================== reduction_sum ==================
op: reduction_sum
doc: Implement the sum along each of the axis dimensions.
args: 
	input :: FLOAT32 REQUIRED
	The feature maps, can be x-dimension.

attrs: 
	axis REQUIRED
	`Datatype`: `vector<int>`

The dimensions to reduce.

	keep_dims REQUIRED
	`Datatype`: `bool`

specify whether the reduced dimension is kept or not.

====================== leaky-relu ==================
op: leaky-relu
doc: Computes the leaky relu function element-wise:

    f(x) = min(x, 0) + alpha * min(x, 0).

args: 
	input :: FLOAT32 REQUIRED
	The feature maps, can be x-dimension.

attrs: 
	alpha REQUIRED
	`Datatype`: `float`

Slope of the activation function at x < 0.

====================== reduction_max ==================
op: reduction_max
doc: Find the maximum value along each of the axis dimensions.
args: 
	input :: FLOAT32 REQUIRED
	The feature maps, can be x-dimension.

attrs: 
	axis REQUIRED
	`Datatype`: `vector<int>`

The dimensions to reduce.

	keep_dims REQUIRED
	`Datatype`: `bool`

specify whether the reduced dimension is kept or not.

====================== pixel-shuffle ==================
op: pixel-shuffle
doc: https://pytorch.org/docs/stable/generated/torch.nn.PixelShuffle.html
args: 
	input :: FLOAT32 REQUIRED
	`[batch, in_height, in_width, in_channels]`.

attrs: 
	scale REQUIRED
	`Datatype`: `int`

scale for PixelShuffle

	upscale REQUIRED
	`Datatype`: `bool`

upscale or downscale PixelShuffle.

====================== l2_normalize ==================
op: l2_normalize
doc: For a 1-D tensor with `axis = 0`, computes

    output = x / sqrt(max(sum(x ^ 2), epsilon))
For x with more dimensions,
independently normalizes each 1-D slice along dimension axis.

args: 
	input :: FLOAT32 REQUIRED
	The feature maps, can be x-dimension.

attrs: 
	axis OPTIONAL
	`Datatype`: `vector<int>`

Dimension along which to normalize.

	epsilon OPTIONAL
	`Datatype`: `double`

A lower bound value for the norm.

====================== data ==================
op: data
doc: A placeholder which stores the float-point input data, 
data operator would always be fed by users.
args: 
attrs: 
	shape REQUIRED
	`Datatype`: `vector<int>`

The shape of the output tensor

	data_type REQUIRED
	`Datatype`: `string`

The data type of the data of output feature maps, we use FLOAT32 as the default.

====================== placeholder ==================
op: placeholder
doc: An interface operator that holds the data. Do nothing here.
args: 
	input :: FLOAT32 REQUIRED
	The feature maps, can be x-dimension.

attrs: 
====================== selu ==================
op: selu
doc: Computes the selu function element-wise:

    f(x) = scale * (max(0, x) + min(0, alpha * (exp(x) - 1))).
alpha and scale are constant value.

args: 
	input :: FLOAT32 REQUIRED
	The feature maps, can be x-dimension.

attrs: 
====================== reshape ==================
op: reshape
doc: Reshape the feature maps or constant data into new shape without changing the layout of data in memory.
args: 
	input :: FLOAT32 REQUIRED
	The feature maps, can be x-dimension.

	shape :: INT32 OPTIONAL
	Constant values that define the shape of the output.

attrs: 
	shape OPTIONAL
	`Datatype`: `vector<int>`

Constant values that define the shape of the output.

